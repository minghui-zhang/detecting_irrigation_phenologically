{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 4: random forest with tuning, using all predictors\n",
    "\n",
    "# set predictors\n",
    "numerical_cols_all = numerical_cols\n",
    "categorical_cols_all = categorical_cols\n",
    "\n",
    "# set tuning space\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] # Number of trees in random forest\n",
    "max_features = ['auto', 'sqrt'] # Number of features to consider at every split\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] # Maximum number of levels in tree\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10] # Minimum number of samples required to split a node\n",
    "min_samples_leaf = [1, 2, 4] # Minimum number of samples required at each leaf node\n",
    "bootstrap = [True, False] # Method of selecting samples for training each tree\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'preprocessor__num__imputer__strategy': ['mean', 'median'],\n",
    "                'rf__n_estimators': n_estimators,\n",
    "               'rf__max_features': max_features,\n",
    "               'rf__max_depth': max_depth,\n",
    "               'rf__min_samples_split': min_samples_split,\n",
    "               'rf__min_samples_leaf': min_samples_leaf,\n",
    "               'rf__bootstrap': bootstrap}\n",
    "\n",
    "# preprocessing pipelines for both numeric and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor_all = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols_all),\n",
    "        ('cat', categorical_transformer, categorical_cols_all)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline\n",
    "pipeline_all = Pipeline(steps=[('preprocessor', preprocessor_all),\n",
    "                      ('rf', RandomForestClassifier())])\n",
    "\n",
    "rf_all_tuned = RandomizedSearchCV(estimator = pipeline_all, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_all_tuned.fit(X_train, y_train)\n",
    "\n",
    "print(rf_all_tuned.best_params_)\n",
    "\n",
    "print((\"best accuracy from grid search, with all features: %.3f\"\n",
    "       % rf_all_tuned.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: {'rf__n_estimators': 1600, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 1, 'rf__max_features': 'sqrt', 'rf__max_depth': None, 'rf__bootstrap': False, 'preprocessor__num__imputer__strategy': 'mean'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all predictors, the tuned model has an accuracy of 0.88; this is slightly higher than the untuned model's accuracy of 0.84, but the gain from tuning when usign all predictors is less than the gain when avoiding geographic predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we used geogrpahic predictors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use it to make predictions of irrigation growth in other years\n",
    "# use only predictors that appear in all years\n",
    "\n",
    "# set predictors\n",
    "numerical_cols_allyears = list(mod_ts_cols_allyears) + phenospectral_cols + missingness_cols\n",
    "numerical_cols_all = numerical_cols_allyears\n",
    "categorical_cols_all = categorical_cols\n",
    "\n",
    "# preprocessing pipelines for both numeric and categorical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor_all = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols_all),\n",
    "        ('cat', categorical_transformer, categorical_cols_all)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline\n",
    "tuned_rf = RandomForestClassifier(n_estimators = 1600, min_samples_split = 2, \n",
    "                                   min_samples_leaf = 1, max_features = 'sqrt', max_depth = None, \n",
    "                                   bootstrap = False)\n",
    "                            \n",
    "pipeline_all = Pipeline(steps=[('preprocessor', preprocessor_all),\n",
    "                      ('rf', tuned_rf)])\n",
    "\n",
    "# training\n",
    "pipeline_all.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "acc_all = pipeline_all.score(X_test, y_test)\n",
    "print(acc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions in new years - using all predictors\n",
    "\n",
    "# data frame to save predicted percent irrigation in each region\n",
    "columns_list = ['year', 'Brazil', 'SUL', 'CENTRO-OESTE', 'SUDESTE', 'NORDESTE', 'NORTE']\n",
    "predicted_irrig_all = pd.DataFrame(columns = columns_list)\n",
    "\n",
    "years_list = list(range(2004, 2014)) + list(range(2015, 2019))\n",
    "\n",
    "for year in years_list:\n",
    "    data_year = pd.read_csv('predictionpts_cleaned_' + str(year) + '.csv', index_col = 0)\n",
    "    chosen_predictors = numerical_cols_all + categorical_cols_all\n",
    "    X_year = data_year[chosen_predictors]\n",
    "\n",
    "    prediction = pipeline_all.predict(X_year)\n",
    "    \n",
    "    data_year['prediction'] = prediction\n",
    "    \n",
    "    # percent irrigated by region\n",
    "    percent_Brazil = prediction.mean()\n",
    "    percent_south = data_year[data_year.region == 'SUL'].prediction.mean()\n",
    "    percent_centerwest = data_year[data_year.region == 'CENTRO-OESTE'].prediction.mean()\n",
    "    percent_southeast = data_year[data_year.region == 'SUDESTE'].prediction.mean()\n",
    "    percent_northeast = data_year[data_year.region == 'NORDESTE'].prediction.mean()\n",
    "    percent_north = data_year[data_year.region == 'NORTE'].prediction.mean()\n",
    "\n",
    "    predicted_irrig_all.loc[len(predicted_irrig_all)] = [year, percent_Brazil, percent_south,\n",
    "                                             percent_centerwest, percent_southeast,\n",
    "                                             percent_northeast, percent_north]\n",
    "    print(year)\n",
    "    \n",
    "print(predicted_irrig_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions\n",
    "\n",
    "tidy_predictions_all = predicted_irrig_all.melt(id_vars = ['year'], value_name = 'percent_irrigated', \n",
    "                                        var_name = 'region')\n",
    "\n",
    "sns.lineplot(x = 'year', y = 'percent_irrigated', data = tidy_predictions_all, hue = 'region')\n",
    "plt.title('Percent irrigation, predicted; using geographic features')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Although the classifer that is trained with geographic information has a high test accuracy, it doesn't reflect the time trends in irrigation expansion as well as a classifier that doesn't include geographic information. The percent irrigation predicted across time looks very similar to what was observed in 2014, indicating that the geographic spread of irrigation in 2014 has an overly strong pull on predicted irrigation in other years."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
